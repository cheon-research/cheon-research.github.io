---
key: NCF
title: "[WWW'17] Neural Collaborative Filtering"
author: "Sangjin Cheon"
tags: WWW17 Recommendation-System Collaborative-Filtering
mathjax: true
---

<img src="https://github.com/cheon-research/cheon-research.github.io/blob/master/assets/post_img/NCF_authors.png?raw=true" width="100%" height="100%">

Paper: [https://arxiv.org/abs/1708.05031](https://arxiv.org/abs/1708.05031){: target="_blank"}  

2017년 WWW에서 발표된 논문으로, Neural Network를 본격적으로 추천 시스템에서 적용하기 시작한 논문입니다. 다른 Side information을 이용하지 않고, 오로지 Rating Matrix만을 이용해서 Collaborative Filtering을 수행하기 때문에, 최근에 나오는 논문들의 baseline에서도 state-of-the-arts 방법 중의 하나로 소개되고 있습니다.  

처음 이 논문을 2018년 말쯤에 봤는데, 당시에는 인용횟수가 약 300회 정도였는데 지금은 1,400회 넘게 인용된걸보고 깜짝 놀랐습니다. 이후에 딥러닝을 추천 시스템에 이용하는 연구들이 상당히 활발하게 이루어졌나 봅니다.  

현재 연구하고 있는 부분과도 맞닿아 있어서 이번 기회에 한번 더 읽어보고 정리해보았습니다.  
  
  
>제가 이해한 내용을 바탕으로 작성되었습니다.  
>완벽하지 않으니 참고해서 봐주시고 의견이 있으시면 댓글이나 메일로 남겨주세요!  
>cheon.research (at) gmail.com  
  
    
# Introduction

개인화 추천 시스템에서는 과거 기록(평점, 클릭,,)을 통해서 아이템에 대한 사용자의 취향(preference)을 모델링하는 것이 중요하다.  
Matrix Factoriazatio(MF)는 사용자와 아이템을 latent space에 projection 시켜서, 사용자나 아이템을 나타내는 latent feature vector를 만들고, 이들의 내적(inner product)로 아이템에 대한 사용자의 interaction을 모델링한다.  
하지만 Latent feature들을 linear하게 곱셈으로 합쳐주는 내적(Inner Product)은 user interaction data의 복잡한 구조를 충분히 캡쳐하기 힘들다.  


# Preliminaries
## Learning from Implicit Data
## Matrix Factorization
<img src="https://github.com/cheon-research/cheon-research.github.io/blob/master/assets/post_img/NCF_figure_1.png?raw=true" width="50%" height="50%">  

# Neural Collaborative Filtering
<img src="https://github.com/cheon-research/cheon-research.github.io/blob/master/assets/post_img/NCF_figure_2.png?raw=true" width="75%" height="75%">  
## General Framework
<img src="https://github.com/cheon-research/cheon-research.github.io/blob/master/assets/post_img/NCF_figure_3.png?raw=true" width="75%" height="75%">  
## Generalized Matrix Factorization(GMF)
Input layer에 사용자(아이템)의 ID를 넣어서 얻는 embedding은 사용자(아이템)의 latent vector라고 볼 수 있다.  
사용자의 latent vector를 $$p_u$$, 아이템의 latent vector를 $$q_i$$라 하면, 아래와 같이 첫번째 neural CF layer를 정의할 수 있다.  
<center>$$\phi_1\left(p_u, q_i\right) = p_u \odot q_i $$</center>  
$$\odot$$는 element-wise product를 나타낸다.  
최종적인 점수 예측을 위해서 아래와 같이 layer를 정의한다.  
<center>$$\hat{y_ui} = a_out\left(h^T\left(p_u \odot q_i\right)\right)$$</center>
$$a_out$$은 activation function을, $$h^T$$는 output layer의 edge weight을 나타낸다.  
$$h$$ 를 통해서 사용자와 아이템의 latent vector를 element-wise product로 얻을 수 있는 vector에서 각 latent dimension의 weight을 학습할 수 있다.  
또한 activation function을 통해서 기존의 linear한 MF 방법에 비해 non-linear한 특성을 표현할 수 있어, 일반화 할수 있다.  
  
  
## Multi-Layer Perceptron(MLP)
## Fusion of GMF and MLP
