---
title:  "[KDD'19] Adversarial Variational Embedding for Robust Semi-supervised Learning"
author: "Sangjin Cheon"
tags: Review KDD'19 Variational-AutoEncoder Generaive-Adversarial-Networks Representation-Learning Semi-supervised-Learning Classification
mathjax: true
comments: true
---

Paper: [https://arxiv.org/abs/1905.02361](https://arxiv.org/abs/1905.02361){: target="_blank"}  
Slide: [https://github.com/cheon-research/paper_reviw_archive/blob/master/200602_AVAE_cheon.pdf](https://github.com/cheon-research/paper_reviw_archive/blob/master/200602_AVAE_cheon.pdf){: target="_blank"}


>제가 이해한 내용을 바탕으로 작성되었습니다.  
>완벽하지 않으니 참고해서 봐주시고 의견이 있으시면 댓글로 남겨주세요!

# Keywords
Variational Autoencoder, Generative Adversarial Networks, Representation Learning, Semi-supervised Classification

# Introduction
![AVAE_figure_1](https://github.com/cheon-research/cheon-research.github.io/blob/master/assets/img/AVAE_figure_1.PNG?raw=true)  
**Figure 1.**  

# Methodology
Dataset을 두개의 subset으로(labelled/unlabelled) 나눈다. 본 논문에서는 distinguishable information이 풍부한 **latent representation**을 학습하는 것이 목표이다.  

Semi-supervised Learning에서는 label이 있는 observation이 부족하기 때문에, label이 없는 데이터로부터 latent variable의 분포를 학습하는 것이 중요하다.

## VAE++
Input observation $$x$$를 $$z_s$$로 압축하고, $$z_s$$를 다시 reconstruction(재구성)해서 original observation을 만든다. (VAE에 대한 자세한 내용은 따로 포스팅 할 예정입니다.) VAE를 통해서 classification이나 generation에 이용될 수 있는 representative latent code $$z_s$$를 학습한다.  

기존의 VAE(standard VAE)는 학습된 latent code $$z_s = g\left(\mu_x, \sigma_x, \varepsilon\right)$$가 **exclusive 하지 않는다**는 한계가 있다. 고정된 ebedding model $$p\left(z_s\mid x\right)$$에서 특정 $$x$$와 이의 latent code $$z_s$$는 prior distribution $$\bar{p}\left(z_s\right)$$에서 랜덤 추출된 stochastic variable $$\varepsilon$$를 포함하고 있기 때문이다.(고정된 모델에 같은 input을 넣어도 $$z_s$$가 매번 다르게 나온다.)  

그래서 논문에서는 exclusive latent code $$z_I$$를 추가한 **VAE++**를 제안한다. 아래의 Figure 2에서 볼 수 있듯, VAE++는 encoder, generator, decoder로 구성되어 있다.  

* Encoder는 observation을 latent code $z_I \in \mathbb{R}^D$로 transform 한다.  
<center>$$p_{\theta_{en}}\left(z_I\mid x\right)=f\left(z_I;x,\theta_{en}\right)$$</center>  

* Generator에서는 $z_I$를 통해 얻을 수 있는 $\mu\left(z_I\right)$와 $\sigma\left(z_I\right)$로 $z_s$를 계산한다.  
<center>$$z_s = \mu\left(z_I\right) + \sigma\left(z_I\right) * \varepsilon$$</center>  

* Decoder는 sample을 reconstruction.  
<center>$$p_{\theta_{de}}\left(x'\mid z_s\right)=f'\left(x';z_s,\theta_{de}\right)$$</center>  

VAE++의 loss function은 다음과 같다.  
<center>$$\mathcal{L}_{VAE}=-\mathbb{E}_{z_s\sim p_{\theta_{en}}\left(z_s\mid x\right)} \left[\log p_{\theta_{en}}\left(x'\mid z_s\right)\right]+KL\left(p_{\theta_{en}}\left(z_s\mid x\right)\mid\mid\bar{p}\left(z_s\right)\right)$$</center>  

* 앞쪽 부분은 reconstruction loss로, observation에 대한 expected negative log-likelihood와 동일하다. 이 부분에서는 decoder가 가우스 분포하에서 $$z_s$$를 기반으로 reconstruct observation $$x$$를 잘 reconstruction하도록 한다. Reconstruction error가 작을수록 encoder가 더 좋은 latent representation을 학습했다는 것을 의미한다.  
  
* 뒷 부분은 Kullback_leibler divergence loss에 해당한다. 이는 latent code의 prior distribution인 $$\bar{p}\left(z_s \right)$$와 posterior distribution인 $$p\left(z_s \mid x \right)$$의 거리를 측정한다. 값이 작을 수록 두 분포가 비슷하다(학습된 분포가 실제 분포와 비슷하다)는 것을 의미한다.  

![AVAE_figure_2](https://github.com/cheon-research/cheon-research.github.io/blob/master/assets/img/AVAE_figure_2.PNG?raw=true)  
**Figure 2.** AVAE(VAE++ and semi-supervised GAN)  

## Adversarial Variational Embedding
위의 Figuer 2를 보면, 제안하는 AVAE에서 generater $$G$$는 standard GAN에서 noise를 사용하는 것 대신에, joint probability $$p\left(\mu, \sigma, \bar{p}\left(z_s\right)\right)$$를 기반으로 $$z_s$$를 생성한다. 생성된 $$z_s$$는 "fake"로, $$z_I$$는 "real" sample로 생각한다. 생성된 sample $$z_s$$를 $$K+1$$번째 class로 간주하여, discriminator에서 class를 분류하도록 한다. 여기서는 label이 있는지 없는지를 따지지 않는다. Discriminator는 다음과 같이 나타낼 수 있다.  
<center>$$q_{\varphi}\left(y_{GAN}\mid z_{GAN}\right)=h\left(y_{GAN};z_{GAN}, \varphi\right)$$</center>  

상황에 따라서 $$z_{GAN}$$이 "fake"인 경우에는 $$q_{\varphi}\left(y_{GAN}=K+1\mid z_{GAN}\right)$$을 사용하고, $$z_{GAN}$$이 "real"인 경우에는 $$q_{\varphi}\left(y_{GAN}\mid z_{GAN}, y_{GAN}<K+1\right)$$을 사용할 수 있다.  

- Labelled input에 대해서는 supervised learning과 동일하게 discriminator가 input $$z_{GAN}$$의 real/fake 여부를 판별하고, 동시에 올바른 class로 분류한다. 따라서 loss function은 다음과 같다. ($$p_j$$는 joint probability를 의미)  
<center>$$\mathcal{L}_{label}=-\mathbb{E}_{z_{GAN}, y_{GAN}\sim p_j} \left[\log q_{\varphi}\left(y_{GAN}\mid z_{GAN}, y_{GAN}<K+1\right)\right]$$</center>
- Unlabelled input에 대해서는 discriminator가 binary classification을 하도록 한다.(real/fake)  
  
<center>$$
\begin{align*}
\mathcal{L}_{unlabel} =& -\mathbb{E}_{z_{GAN}\sim p_{\theta_{en}}\left(z_s\mid x\right)} \left[\log\left(1-q_{\varphi}\left(y_{GAN}=<K+1\mid z_{GAN}\right)\right)\right] \\
& -\mathbb{E}_{z_{GAN}\sim p_{\theta_{en}}\left(z_s\mid x\right)} \left[\log\left(q_{\varphi}\left(y_{GAN}=<K+1\mid z_{GAN}\right)\right)\right]
\end{align*}
$$</center>

Discriminator의 최종적인 loss function은 다음과 같다. ($$w_1$$과 $$w_2$$는 weight, $$flag$$는 labelled input일때 1, unlabelled 이면 0을 나타낸다.)  

<center>$$\mathcal{L}_{GAN}=w_1*flag*\mathcal{L}_{label}+w_2*\left(1-flag\right)*\mathcal{L}_{unlabel}$$</center>  

추가로 $$\mathcal{L}_{unlabel}$$이 $$\mathcal{L}_{label}$$보다 훨씬 쉽게 수렴하고, real/fake classification의 정확도가 $$K$$ class classification의 정확도보다 훨씬 높기 때문에 본 논문의 실험에서는 $$w_1=0.9$$, $$w_2=0.1$$로 설정했다고 합니다.  

최종적으로 학습을 마치면(수렴하면) compressed representative code $$z_I$$를 classification에 이용합니다.  

